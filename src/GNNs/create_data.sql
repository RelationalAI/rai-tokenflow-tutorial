/* Step 1: Upload data and create a schema */

-- prepare a schema where we will put the raw data
USE DATABASE GNN_TOKENFLOW;
CREATE SCHEMA IF NOT EXISTS RAW_DATA;
-- now upload thie file from the repo /data/token-trades.csv'
-- create a table named TOKENFLOW_TRADES_RAW

/* Step 2:
Database Table creation for GNNs
We will create three tables:
BUYERS, SENDERS AND TRANSACTIONS, we will use a new
SCHEMA to store the clean data
*/
CREATE SCHEMA IF NOT EXISTS GNN_TOKENFLOW.DATA;

-- create BUYERS table
CREATE OR REPLACE TABLE GNN_TOKENFLOW.DATA.BUYERS AS
SELECT DISTINCT CAST(BUY_TOKEN_ADDRESS AS STRING) AS BUY_TOKEN_ADDRESS
FROM GNN_TOKENFLOW.RAW_DATA.TOKENFLOW_TRADES_RAW;

-- create SENDERS TABLE
CREATE OR REPLACE TABLE GNN_TOKENFLOW.DATA.SENDERS AS
SELECT DISTINCT CAST(TX_SENDER_ADDRESS AS STRING) AS TX_SENDER_ADDRESS
FROM GNN_TOKENFLOW.RAW_DATA.TOKENFLOW_TRADES_RAW;

-- transactions table 
-- for simplicity we'll modify the timestamp to YYYYMMDD
CREATE OR REPLACE TABLE GNN_TOKENFLOW.DATA.TRANSACTIONS AS
SELECT 
    CAST(TX_SENDER_ADDRESS AS STRING) AS TX_SENDER_ADDRESS,
    CAST(BUY_TOKEN_ADDRESS AS STRING) AS BUY_TOKEN_ADDRESS,
    CAST(BLOCK_TIMESTAMP AS DATE) AS BLOCK_TIMESTAMP,
    BUY_AMOUNT,
    BUY_TOKEN_SYMBOL,
    SELL_TOKEN_SYMBOL,
    SELL_AMOUNT
FROM GNN_TOKENFLOW.RAW_DATA.TOKENFLOW_TRADES_RAW;

/* Step 3:
Create data for training, we refer to this as task tables.
We will also create a new schema for the task tables
*/

-- create a schema to store the task data
CREATE SCHEMA IF NOT EXISTS GNN_TOKENFLOW.TASK;

SET train_start_date = '2014-10-21';
SET train_end_date = '2025-01-16';
SET val_date = '2025-01-17';
SET test_date = '2025-01-27';

CREATE OR REPLACE TABLE GNN_TOKENFLOW.TASK.VALIDATION AS
SELECT
    TX_SENDER_ADDRESS,
    BLOCK_TIMESTAMP,
    -- in link prediction problems destination entities must by a list
    ARRAY_AGG(BUY_TOKEN_ADDRESS) AS BUY_TOKEN_ADDRESS
FROM GNN_TOKENFLOW.DATA.TRANSACTIONS
WHERE BLOCK_TIMESTAMP = $val_date
GROUP BY TX_SENDER_ADDRESS, BLOCK_TIMESTAMP;

CREATE OR REPLACE TABLE GNN_TOKENFLOW.TASK.TEST AS
SELECT
    TX_SENDER_ADDRESS,
    BLOCK_TIMESTAMP,
    -- in link prediction problems destination entities must by a list
    ARRAY_AGG(BUY_TOKEN_ADDRESS) AS BUY_TOKEN_ADDRESS
FROM GNN_TOKENFLOW.DATA.TRANSACTIONS
WHERE BLOCK_TIMESTAMP = $test_date
GROUP BY TX_SENDER_ADDRESS, BLOCK_TIMESTAMP;

CREATE OR REPLACE TABLE GNN_TOKENFLOW.TASK.TRAIN AS
SELECT
    TX_SENDER_ADDRESS,
    BLOCK_TIMESTAMP,
    -- in link prediction problems destination entities must by a list
    ARRAY_AGG(BUY_TOKEN_ADDRESS) AS BUY_TOKEN_ADDRESS
FROM GNN_TOKENFLOW.DATA.TRANSACTIONS
WHERE BLOCK_TIMESTAMP >= $train_start_date and BLOCK_TIMESTAMP < $train_end_date
GROUP BY TX_SENDER_ADDRESS, BLOCK_TIMESTAMP;

/* Step 4: Grant access to the relationalAI APP */

-- here we grant access to all schemas and tables, you might want to
-- select specific tables and schemas to grant access to
GRANT USAGE ON DATABASE GNN_TOKENFLOW TO APPLICATION RELATIONALAI;
GRANT USAGE ON ALL SCHEMAS IN DATABASE GNN_TOKENFLOW TO APPLICATION RELATIONALAI;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN DATABASE GNN_TOKENFLOW TO APPLICATION RELATIONALAI;
-- grant write access to write results, we encourage the user to select specific schemas
-- to give write access to
GRANT CREATE TABLE ON ALL SCHEMAS IN DATABASE GNN_TOKENFLOW TO APPLICATION RELATIONALAI;

